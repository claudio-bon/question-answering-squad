# -*- coding: utf-8 -*-

import collections
from tqdm.auto import tqdm


Position = collections.namedtuple("Position", ["start","end"])
Score = collections.namedtuple("Score", ["index","score"])


def get_best_feasible_position(start_logits, end_logits, context_start, context_end, n_logits=0.15):
    """
    This function goes through the start logits and end logits (likelihood that the
    corresponding token is the start and end of the answer rispectively) and
    select the couple that maximize their summation on one hand and that respect
    the consistency constraints on the other.
    The consistency constraints are:
        - The start of the answer cannot be after it's end.
        - The answer cannot be overlapped with the question.

    Parameters
    ----------
    start_logits : torch.tensor
        Tensor long as the input sequence (tokenized question plus context).
        Each index holds the likelihood that the corresponding token is the
        start of the answer.
    end_logits : torch.tensor
        Tensor long as the input sequence (tokenized question plus context).
        Each index holds the likelihood that the corresponding token is the
        end of the answer.
    context_start : int
        Index of the context's first token inside the tokenized sequence (which
        is composed by both the question and the context).
    context_end : int
        Index of the context's last token inside the tokenized sequence (which
        is composed by both the question and the context).
    n_logits : float
        Percentage of logits used to find the best answer placement inside the
        context.

    Raises
    ------
    ValueError
        Raised in case no coherent pair of starting and ending positions have
        been found.

    Returns
    -------
    collections.namedtuple
        Holds the index of the answer's starting and ending token.

    """
    #Sort logits in ascending order
    #Sort logits in ascending order
    sorted_start_logit = sorted(enumerate(start_logits), key=lambda x: x[1], reverse=True)[:int(len(start_logits)*n_logits)]
    sorted_end_logit = sorted(enumerate(end_logits), key=lambda x: x[1], reverse=True)[:int(len(end_logits)*n_logits)]

    # Associate the positions of each pair of start and end tokens to their score and sort them in descending order of score
    sorted_scores = collections.OrderedDict(
                            sorted({Position(start=i, end=j):sl+el for i,sl in sorted_start_logit for j,el in sorted_end_logit}.items(),
                                    key=lambda x: x[1],
                                    reverse=True)
                    )
    
    # Return the position of the pair of higher score that respects the consistency constraints
    return next(Score(index=pos, score=score) for pos,score in sorted_scores.items() \
                if pos.start <= pos.end and pos.start >= context_start and pos.end <= context_end)

def map_feature_to_row(dataset, features):
    """
    This function associates the dataset's row's index (computed from the
    original row's id) with the ids of all the features generated by the said row.

    Parameters
    ----------
    row : datasets.Dataset
        Dataset used to make the prediction.
    features : transformers.BatchEncoding
        Features obtained through dataset's preprocessing.

    Returns
    -------
    features_per_row : collections.defaultdict
        Dictionary that associate the dataset's row's index (computed from the
        original row's id) with the ids of all the features generated by the said row.

    """
    # Associate rows' id with an index
    row_id_to_index = {k: i for i, k in enumerate(dataset["id"])}
    features_per_row = collections.defaultdict(list)
    # Create a corrispondence beween the previously computed rows' index with
    # the index of the features that belong to the said rows
    for i, feature in enumerate(features):
        features_per_row[row_id_to_index[feature["row_id"]]].append(i)

    return features_per_row

def postprocess_eval(dataset, features, raw_predictions, verbose=True):
    """
    Processes the raw predictions in order to transform it in a textual answer.

    Parameters
    ----------
    dataset : datasets.Dataset
        Dataset used to make the prediction.
    features : transformers.BatchEncoding
        features generated by rows through the preprocessing step.
    raw_predictions : collections.namedtuple
        Predictions done using the features.
    verbose : boolean, optional
        If True it also print additional informations. The default is True.

    Returns
    -------
    predictions : collections.OrderedDict
        Dictionary containing as keys the id of the row that generated the prediction
        and as values the textual answer that stems from such prediction.

    """
    all_start_logits, all_end_logits = raw_predictions

    # Map the dataset's rows to their corresponding features.
    features_per_row = map_feature_to_row(dataset, features)

    predictions = collections.OrderedDict()

    if verbose:
        print(f"Post-processing {len(dataset)} dataset predictions split into {len(features)} features.")

    for row_index, row in enumerate(tqdm(dataset)):
        valid_answers = []

        # Indices of the features associated to the current row.
        feature_indices = features_per_row[row_index]
        
        context = row["context"]
        # Loop on the features associated to the current row.
        for feature_index in feature_indices:
            context_start = features[feature_index]["context_start"]
            context_end = features[feature_index]["context_end"]

            offsets = features[feature_index]["offset_mapping"]

            # Computation of the answer from the raw preditions.
            start_logits = all_start_logits[feature_index]
            end_logits = all_end_logits[feature_index]
            try:
                valid_answers.append(get_best_feasible_position(start_logits, end_logits, context_start, context_end))
            except StopIteration:
                continue

        # For each row use as answer the best candidate generated by the row's features
        if len(valid_answers) > 0:
            answer_pos = sorted(valid_answers, key=lambda x: x.score, reverse=True)[0].index
            answer = context[offsets[answer_pos.start][0]: offsets[answer_pos.end][1]]
        # In case no candidates are found return an empty string
        else:
            print("Not found any consistent answer's start and/or end")
            answer = ""

        predictions[row["id"]] = answer

    return predictions